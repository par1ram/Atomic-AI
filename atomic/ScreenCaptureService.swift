//
//  ScreenCaptureService.swift
//  atomic
//
//  –°–µ—Ä–≤–∏—Å –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ —ç–∫—Ä–∞–Ω–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ OCR

import Foundation
import ScreenCaptureKit
import Vision

class ScreenCaptureService {
    // MARK: - Constants

    private enum Constants {
        static let captureInterval: UInt64 = 3_000_000_000 // 3 seconds in nanoseconds
        static let ocrLanguages = ["ru-RU", "en-US"]
    }

    // MARK: - Properties

    private var latestText = ""
    private var captureTask: Task<Void, Never>?
    private var isCaptureInProgress = false

    func startCapture() throws {
        // –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –∑–∞—Ö–≤–∞—Ç —ç–∫—Ä–∞–Ω–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏
        captureTask = Task {
            while !Task.isCancelled {
                if !isCaptureInProgress {
                    await captureAndExtractText()
                }

                // –ó–∞—Ö–≤–∞—Ç –∫–∞–∂–¥—ã–µ 3 —Å–µ–∫—É–Ω–¥—ã (–±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å—é –∏ –Ω–∞–≥—Ä—É–∑–∫–æ–π)
                try? await Task.sleep(nanoseconds: Constants.captureInterval)
            }
        }
    }

    func stopCapture() {
        captureTask?.cancel()
        captureTask = nil
    }

    func getLatestText() -> String {
        return latestText
    }

    func clearText() {
        latestText = ""
        print("üßπ –¢–µ–∫—Å—Ç —Å —ç–∫—Ä–∞–Ω–∞ –æ—á–∏—â–µ–Ω")
    }

    private func captureAndExtractText() async {
        isCaptureInProgress = true
        defer { isCaptureInProgress = false }

        do {
            // –ü–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∏—Å–ø–ª–µ–∏
            let content = try await SCShareableContent.current

            guard let display = content.displays.first else {
                print("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∏—Å–ø–ª–µ–µ–≤ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞")
                return
            }

            // –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞
            let filter = SCContentFilter(display: display, excludingWindows: [])
            let configuration = SCStreamConfiguration()

            // –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Ç–∏–≤–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —ç–∫—Ä–∞–Ω–∞ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ OCR
            configuration.width = display.width
            configuration.height = display.height
            configuration.pixelFormat = kCVPixelFormatType_32BGRA

            // –ó–∞—Ö–≤–∞—Ç–∏—Ç—å –∫–∞–¥—Ä
            let image = try await SCScreenshotManager.captureImage(
                contentFilter: filter,
                configuration: configuration
            )

            // –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é Vision
            let text = await extractText(from: image)

            if !text.isEmpty {
                latestText = text
                print("üì∏ –ó–∞—Ö–≤–∞—á–µ–Ω —Ç–µ–∫—Å—Ç —Å —ç–∫—Ä–∞–Ω–∞ (\(text.count) —Å–∏–º–≤–æ–ª–æ–≤)")
            }

        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞ —ç–∫—Ä–∞–Ω–∞: \(error.localizedDescription)")
        }
    }

    private func extractText(from cgImage: CGImage) async -> String {
        await withCheckedContinuation { continuation in
            let request = VNRecognizeTextRequest { request, error in
                guard error == nil else {
                    continuation.resume(returning: "")
                    return
                }

                let observations = request.results as? [VNRecognizedTextObservation] ?? []
                let text = observations.compactMap { observation in
                    observation.topCandidates(1).first?.string
                }.joined(separator: " ")

                continuation.resume(returning: text)
            }

            request.recognitionLevel = .accurate
            request.recognitionLanguages = Constants.ocrLanguages
            request.usesLanguageCorrection = true

            let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
            try? handler.perform([request])
        }
    }
}
